{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30619103",
   "metadata": {},
   "source": [
    "### Задача 1 \n",
    "\n",
    "Дописать функцию с выбором действий на основе ВДГ-действий `get_action()` и\n",
    "дописать симуляцию бандита с выбором действий по стратегии с выборкой Томпсона (+0,5 буквы).\n",
    "\n",
    "См. файл `2.0 RL_MAB_on.ipynb`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b124ddc3-76db-4c1d-a486-5eb25bca9aa9",
   "metadata": {},
   "source": [
    "### Задача 2\n",
    "\n",
    "Реализовать точный метод оценки стратегии через решение СЛАУ (+0,5 буквы).\n",
    "\n",
    "См. файл `2.1.1 RL_DP_PolicyEval_on.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ae7c3e",
   "metadata": {},
   "source": [
    "### Задача 3\n",
    "\n",
    "Дописать алгоритм итерации по ценности для поиска оптимальной стратегии (+0,5 буквы).\n",
    "\n",
    "См. файл `2.1.2 RL_DP_OptimalPolicy_on.ipynb`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793b3710",
   "metadata": {},
   "source": [
    "### Задача 4\n",
    "\n",
    "Реализовать метод Монте-Карло для поиска оптимальной стратегии с исследовательскими стартами, сравнить $\n",
    "varepsilon$-жадную стратегию и жадную но с исследовательскими стартами на примере среды `FrozenLake`  (+0,5 буквы).\n",
    "\n",
    "См. файл: `2.2.1 RL_MC_OptimalPolicy_on.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2250575e",
   "metadata": {},
   "source": [
    "### Задача 5\n",
    "\n",
    "Реализовать обучение табличного агента на основе метода ExpectedSARSA, как метода обучения с единой стратегией с обобщённой итерацией по $\\varepsilon$-жадным стратегиям  (+0,5 буквы).\n",
    "\n",
    "См. файл: `2.3.2 RL_TD_ExpectedSARSA_on.ipynb`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bdf9d5-eeb2-4793-a5f8-8f24264c7e69",
   "metadata": {},
   "source": [
    "### Задача 6\n",
    "\n",
    "Обучить агента одним из изученных выше методов взаимодействию со средой \n",
    "\n",
    "    env = gym.make(\"Acrobot-v1\")\n",
    "\n",
    "Базовое описание среды можно найти по ссылке:\n",
    "\n",
    "    https://gymnasium.farama.org/environments/classic_control/acrobot/\n",
    "\n",
    "Цель в обучении агента до такого уровня, чтобы при прогоне на 1000 эпизодах средний доход превысил -105  (+0,5 буквы).\n",
    "Если средний доход превысит -85, то +1 буква.\n",
    "\n",
    "См. файл `2.3.4 RL_TD_N_step_SARSA_on.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fac1049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6489e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff98cf04",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
