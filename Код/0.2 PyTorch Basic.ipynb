{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e0f5e62",
   "metadata": {},
   "source": [
    "# PyTorch: основы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fedc5e7",
   "metadata": {},
   "source": [
    "**PyTorch** - это библиотека (или фреймворк) с функционалом для решения задач глубокого обучения. Есть несколько такого типа библиотек. Разница между ними в общем принципе вычислений. В **PyTorch** граф вычислений динамический, он создаётся по ходу вычисления выражений (то есть существует только во время выполнения, потом он \"разрушается\", в отличие от статических графов, которые компилируются один раз и затем используются без изменения). \n",
    "\n",
    "Условно **PyTorch** можно описать формулой:  \n",
    "\n",
    "$$PyTorch = NumPy + CUDA + Autograd$$\n",
    "\n",
    "Установленную версию **PyTorch** можно узнать следующей командой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aea9468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0+cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e98e406",
   "metadata": {},
   "source": [
    "При использовании Google Colab чтобы использовать GPU как среду выполнения команд, надо в меню Runtime выбрать Change runtime type и в появившемся окне выбрать GPU. Характеристики GPU в Google Colab можно узнать командой\n",
    "\n",
    "    !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f163db14",
   "metadata": {},
   "source": [
    "### Тензоры: создание\n",
    "\n",
    "Основным типом данных для работы в **PyTorch** является тензор. В контексте глубокого обучения, под тензором понимается многомерный массив. Например, тензор размерности 2 - то числовая матрица, тензор размерности 3 - это матрица, элементами которой являются вектора из некоторого ${\\mathbb R}^d$ и т.д. В рамках глубокого обучения данные представляются именно в виде тензоров (изображения, аудио, видео и т.д.)\n",
    "\n",
    "Рассмотрим простейшие способы создать тензоры различных размеров. Основные характеристики тензора - это его размерность и размер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "adca19d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n",
      "0\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# Тензор-скаляр\n",
    "scalar = torch.tensor(7)\n",
    "print(scalar)\n",
    "print(scalar.ndim)\n",
    "print(scalar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7793944c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получить число с типом данных int в данном случае (только для одно-элементных тензоров)\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3acd8fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Команда type для тензоров \n",
    "type(scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c23390a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 7])\n",
      "1\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Тензор-вектор\n",
    "vector = torch.tensor([7, 7])\n",
    "print(vector)\n",
    "print(vector.ndim)\n",
    "print(vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f4b72fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7,  8],\n",
      "        [ 9, 10]])\n",
      "2\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Тензор-матрица\n",
    "MATRIX = torch.tensor([[7, 8], \n",
    "                       [9, 10]])\n",
    "print(MATRIX)\n",
    "print(MATRIX.ndim)\n",
    "print(MATRIX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b762e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [3, 6, 9],\n",
      "         [2, 4, 5]]])\n",
      "3\n",
      "torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# 3-мерный тензор\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]]])\n",
    "print(TENSOR)\n",
    "print(TENSOR.ndim)\n",
    "print(TENSOR.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb0afb7",
   "metadata": {},
   "source": [
    "Часто необходимо создать тензор заданного размера со случаными значениями. \n",
    "Это делается командой torch.rand() отправив туда размер тензора. Значения являются реализацией случайной величины с нормальным распределением. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1af222d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9180, 0.1817, 0.6840, 0.2881],\n",
       "        [0.5334, 0.0741, 0.2673, 0.4864],\n",
       "        [0.4803, 0.3563, 0.3182, 0.1908]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создание матрицы размера (3, 4)\n",
    "random_tensor = torch.rand(3, 4)\n",
    "# либо так\n",
    "random_tensor = torch.rand(size=(3, 4))\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f719950",
   "metadata": {},
   "source": [
    "Также, часто необходимо создать тензор, заданного размера, со значениями 0 или 1. Для этого также есть специальные команды.\n",
    "\n",
    "Кроме того, есть возможность создать тензор из нулей или единиц того же размера, что и заданный тензор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "677bd8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]) \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Тензор из нулей\n",
    "zeros = torch.zeros(size=(3, 4))\n",
    "\n",
    "# Тензор из единиц\n",
    "ones = torch.ones(size=(4, 3))\n",
    "print(zeros,'\\n',ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f994f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "new_zeros = torch.zeros_like(input=ones) \n",
    "print(new_zeros)\n",
    "new_ones = torch.ones_like(input=zeros) \n",
    "print(new_ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c77b00c",
   "metadata": {},
   "source": [
    "Также, можно создавать тензоры с помощью итератора. Это делается командой `torch.arange(start, end, step)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a25a875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.arange(start=0, end=10, step=1)\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d898706",
   "metadata": {},
   "source": [
    "Также тензор можно создать, передав размеры специальному конструктору тензоров, например torch.FloatTensor(). По умолчанию значения при этом заполняются случайными близкими к нулю значениями. Для иницализации именно нулями, можно использовать метод zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "42131080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.7753e+28, 1.3458e-14, 2.5171e-12],\n",
      "         [2.5455e-12, 8.2495e+17, 7.2296e+31],\n",
      "         [5.6015e-02, 4.4721e+21, 1.8042e+28]],\n",
      "\n",
      "        [[3.9569e-14, 7.2143e+22, 4.7428e+30],\n",
      "         [1.3583e-19, 1.3567e-19, 1.4586e-19],\n",
      "         [8.3408e+17, 7.2296e+31, 5.6015e-02]]])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(size=(2,3,3)) \n",
    "print(x)\n",
    "x = torch.FloatTensor(size=(10,)).zero_() # для инициализации нулями\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19db65d0",
   "metadata": {},
   "source": [
    "### Тензоры: типы данных\n",
    "\n",
    "В **PyTorch** для тензоров используется несколько специальных типов данных, например `FloatTensor`, `IntTensor`, `ByteTensor`. См. подробнее по ссылке\n",
    "\n",
    "https://pytorch.org/docs/stable/tensors.html#data-types\n",
    "    \n",
    "Создать тензор с нужным типов данных можно из массивов в **Python**, приведя их к одному из тензорных типов. Тип данных для чисел с плавающей точкой по умолчанию - это 32-битное число с плавающей точкой `torch.float32` или `torch.float`\n",
    "\n",
    "Тип данных для целых чисел по умолчанию - это 64-битное целое число `torch.int64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c95dd274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "v = torch.tensor([7, 7])\n",
    "print(v.dtype) # тип данных в тензоре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9caba9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "b = torch.tensor([[1.0,2,3], [4,5,6]])\n",
    "print(b.dtype) # тип данных в тензоре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "89eee4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float16, device(type='cpu'))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=torch.float16, # если None или ничего, то torch.float32\n",
    "                               device=None, # размещение тензора для вычислений на CPU или GPU\n",
    "                               requires_grad=False) # если True, то операции над тензором записываются\n",
    "\n",
    "float_tensor.shape, float_tensor.dtype, float_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfad0d2f",
   "metadata": {},
   "source": [
    "Меньшая точность - быстрые, но менее точные вычисления.\n",
    "\n",
    "Самые частые ошибки при работе с тензорами:\n",
    "1. несовместный размер для проведения той или иной операции\n",
    "2. не одиннаковый тип данных при проведении операции\n",
    "3. тензоры на разных device\n",
    "\n",
    "Три самых важных аттрибута тензоров:\n",
    "\n",
    "    shape - размерность\n",
    "    dtype - тип данных\n",
    "    device - на каком из device (GPU or CPU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "acb72dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4052, 0.2472, 0.7881, 0.2938],\n",
      "        [0.1416, 0.1619, 0.3780, 0.4837],\n",
      "        [0.5292, 0.2393, 0.8241, 0.1893]])\n",
      "Размерность: torch.Size([3, 4])\n",
      "Тип данных: torch.float32\n",
      "Device для хранения: cpu\n"
     ]
    }
   ],
   "source": [
    "some_tensor = torch.rand(3, 4)\n",
    "\n",
    "print(some_tensor)\n",
    "print(f\"Размерность: {some_tensor.shape}\")\n",
    "print(f\"Тип данных: {some_tensor.dtype}\")\n",
    "print(f\"Device для хранения: {some_tensor.device}\") # по умолчанию на CPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f2755b",
   "metadata": {},
   "source": [
    "Для изменения типа данных тензора: используется метод`type_as()`. При этом создаётся новый тензор (старый не меняется).\n",
    "\n",
    "Второй способ это функция `torch.Tensor.type(dtype=None)`, где параметром dtype можно задать тот тип данных, который требуется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e28b2d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  3, -7], dtype=torch.int32)\n",
      "tensor([  1,   3, 249], dtype=torch.uint8)\n",
      "tensor([ 1.5000,  3.1992, -7.0000], dtype=torch.float16)\n",
      "tensor([ 1,  3, -7], dtype=torch.int8)\n",
      "tensor([ 1.5000,  3.2000, -7.0000])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1.5, 3.2, -7])\n",
    "print(a.type_as(torch.IntTensor()))\n",
    "print(a.type_as(torch.ByteTensor()))\n",
    "print(a.type(torch.float16))\n",
    "print(a.type(torch.int8))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3a218d",
   "metadata": {},
   "source": [
    "### Тензоры: арифметические и матричные операции\n",
    "\n",
    "Сначала рассмотрим операции, где операнды это тензор и число. В этом случае действие с числом применяется к каждому элементу тензора. Все эти операции не меняют исходные тензоры, а создают новые."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1aa05d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 12, 13])\n",
      "tensor([10, 20, 30])\n",
      "tensor([-9, -8, -7])\n",
      "tensor([0.1000, 0.2000, 0.3000])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(tensor + 10)\n",
    "print(tensor * 10)\n",
    "print(tensor - 10)\n",
    "print(tensor / 10)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9574142b",
   "metadata": {},
   "source": [
    "Поэлементнтые **Арифметические операции**, где операнды это тензора одного размера, работают также, как и в NumPy, но рекомендуется использовать их **PyTorch** аналоги  \n",
    "\n",
    "| Оператор | Аналог |\n",
    "|:-:|:-:|\n",
    "|`+`| `torch.add()` |\n",
    "|`-`| `torch.sub()` |\n",
    "|`*`| `torch.mul()` |\n",
    "|`/`| `torch.div()` |\n",
    "\n",
    "Все эти операции не меняют исходные тензоры, а создают новые."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85f22bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 22, 33]) , tensor([11, 22, 33])\n",
      "tensor([ -9, -18, -27]) , tensor([ -9, -18, -27])\n",
      "tensor([10, 40, 90]) , tensor([10, 40, 90])\n",
      "tensor([0.1000, 0.1000, 0.1000]) , tensor([0.1000, 0.1000, 0.1000])\n",
      "tensor([1, 2, 3]) , tensor([10, 20, 30])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([10, 20, 30])\n",
    "print(torch.add(a,b),\",\",a+b)\n",
    "print(torch.sub(a,b),\",\",a-b)\n",
    "print(torch.mul(a,b),\",\",a*b)\n",
    "print(torch.div(a,b),\",\",a/b)\n",
    "print(a,\",\",b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08139221",
   "metadata": {},
   "source": [
    "Матричные операции также реализованы в специальных методах: умножение матриц, умножение матрицу на вектор и скаларное произведение векторов. Эти методы также создают новый тензор для результата."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23172b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11.0778, 11.1836],\n",
      "        [ 9.8551, 10.0431]])\n",
      "tensor([14.7985, 13.0741])\n",
      "tensor(33.3321)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(size=(2,3))+1\n",
    "y = torch.rand(size=(3,2))+2\n",
    "v = torch.rand(size=(3,))+3\n",
    "\n",
    "# Умножение матриц: 5 различных способов записи\n",
    "z = x.mm(y) \n",
    "z = x.matmul(y)\n",
    "z = torch.mm(x, y)\n",
    "z = torch.matmul(x, y)\n",
    "z = x @ y  \n",
    "print(z)\n",
    " \n",
    "# Умножение матрицы на вектор\n",
    "z = x.mv(v) \n",
    "z = torch.mv(x, v)\n",
    "print(z)\n",
    "\n",
    "# Скалярное умножение векторов\n",
    "z = v.dot(v)  \n",
    "z = torch.dot(v, v)\n",
    "z = v @ v\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3895c3",
   "metadata": {},
   "source": [
    "Самая типичная ошибка при перемножении матриц - это не соответствие размерностей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdd2ce24",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-6268f3558443>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "x = torch.rand(size=(3,2))+1\n",
    "y = torch.rand(size=(3,2))+2\n",
    "z = torch.matmul(x, y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4876d8ba",
   "metadata": {},
   "source": [
    "Ещё одна полезна операция - это транспозиция, то есть смена размерностей в тензоре. Есть два способа. Простой способ `tensor.T` или `torch.t(tensor)` для матриц, где tensor тензор, который надо транспонировать. Если на вход подаются вектора, то они не изменяются. Тензоры размерности больше 2 выдают ошибку. Опять же при вызове создаётся новый тензор, а не меняется старый.\n",
    "\n",
    "Более общий способ `torch.transpose(input, dim0, dim1)`, где input тензор на входе, dim0 и dim1 размерности, который надо поменять местами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e619cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1443, 1.3227],\n",
      "        [1.7052, 1.3934],\n",
      "        [1.8932, 1.5606]])\n",
      "tensor([[1.1443, 1.7052, 1.8932],\n",
      "        [1.3227, 1.3934, 1.5606]])\n",
      "tensor([[1.1443, 1.7052, 1.8932],\n",
      "        [1.3227, 1.3934, 1.5606]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(size=(3,2))+1\n",
    "print(x)\n",
    "print(x.T)\n",
    "print(torch.t(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561dde78",
   "metadata": {},
   "source": [
    "Матричное умножение также можно осуществлять как перемножение вектора матриц на вектор матриц (или перемножение батчей с матрицами)\n",
    "То есть первый батч или тензор имеет размер $(b \\times n \\times m)$, второй --  $(b \\times m \\times p)$, тогда результат имеет размер $(b \\times n \\times p)$. Для этого есть специальная функция `bmm()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "157c0134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx = torch.FloatTensor(5,2,3)+1 \n",
    "by = torch.FloatTensor(5,3,2)+2\n",
    "\n",
    "bz = bx.bmm(by)  #Перемножает батчей матриц\n",
    "bz = torch.bmm(bx, by)\n",
    "bz.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319bb254",
   "metadata": {},
   "source": [
    "### Тензоры: прочие стандартные операции"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8be15ab",
   "metadata": {},
   "source": [
    "Также в классе тензоров реализованы методы для поиска суммы элементов, среднего, максимума, минимума вдоль той или иной оси. Методы .max() и .min() также возвращают индексы максимальных/минимальных элементов по указанной оси."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "297c0b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(666.) , tensor(666.)\n",
      "tensor(74.) , tensor(74.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3], [10, 20, 30], [100, 200, 300]], dtype=torch.float)\n",
    "\n",
    "# сумма всех элементов тензора и среднее всех элементов тензора, 2 формы записи\n",
    "print(a.sum(),\",\",torch.sum(a))\n",
    "print(a.mean(),\",\",torch.mean(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa52d10",
   "metadata": {},
   "source": [
    "Функция mean() работает не со всеми типами данных, тензор целых чисел вызовет ошибку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4fbc15f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-9024bc1e59b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
     ]
    }
   ],
   "source": [
    "b = torch.tensor([[1, 2, 3], [10, 20, 30], [100, 200, 300]])\n",
    "\n",
    "print(b.mean(),\",\",torch.mean(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e216e33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([111., 222., 333.]) , tensor([111., 222., 333.])\n",
      "tensor([  6.,  60., 600.]) , tensor([  6.,  60., 600.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3], [10, 20, 30], [100, 200, 300]], dtype=torch.float)\n",
    "\n",
    "# в аргументе можно также указать индекс оси, вдоль которой проводить сумимрование или искать среднее\n",
    "print(a.sum(0),\",\",torch.sum(a,0))\n",
    "print(a.sum(1),\",\",torch.sum(a,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd8e9aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(300.) , tensor(300.)\n",
      "tensor(1.) , tensor(1.)\n",
      "torch.return_types.min(\n",
      "values=tensor([1., 2., 3.]),\n",
      "indices=tensor([0, 0, 0])) , torch.return_types.min(\n",
      "values=tensor([1., 2., 3.]),\n",
      "indices=tensor([0, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "# максимальный и минимальный элемент массива\n",
    "print(a.max(),\",\",torch.max(a))\n",
    "print(a.min(),\",\",torch.min(a))\n",
    "\n",
    "# максимальный и минимальный элемент массива вдоль оси, возвращаются также индексы соответствующих элементов\n",
    "# например, минимум вдоль оси 0 выдаст строку минимумов  (min(a[0,:]), min(a[1,:]),...)\n",
    "print(a.min(0),\",\",torch.min(a,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ebf432",
   "metadata": {},
   "source": [
    "Например, рассмотрим тензор `a` размерности (100, 780, 780, 3), который можно интерпретировать как 100 изображений размера 780х780 с тремя цветовыми каналами. Тогда среднее элементов по 1-ой оси, означает усреднённое изображение по всем изображениям. А среднее по 4-ой оси значит усреднение каналов для каждого изображения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87da20e5",
   "metadata": {},
   "source": [
    "Помимо нахождения максимума или минимума полезно также возвращать позицию этих значений в тензоре. Для этого используются функции `torch.argmax()` и `torch.argmin()`. Если значений максимума и минимума несколько, то возвращается индекс первого."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ad18c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([0, 1, 2, 3, 2, 1, 0, 3])\n",
      "Индекс максимума: 3\n",
      "Индекс минимума: 0\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([0,1,2,3,2,1,0,3])\n",
    "print(f\"Tensor: {tensor}\")\n",
    "\n",
    "\n",
    "print(f\"Индекс максимума: {tensor.argmax()}\")\n",
    "print(f\"Индекс минимума: {tensor.argmin()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36ebac6",
   "metadata": {},
   "source": [
    "Для тензоров равного размера можно также определить **булевы операции**. Они работают также, как и в NumPy, но рекомендуется использовать их **PyTorch** аналоги  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11975a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False],\n",
      "        [False, False, False],\n",
      "        [ True,  True,  True]])\n",
      "tensor([[ True,  True,  True],\n",
      "        [ True,  True,  True],\n",
      "        [False, False, False]])\n",
      "tensor([[False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False]])\n",
      "tensor([[ True,  True,  True],\n",
      "        [ True,  True,  True],\n",
      "        [False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "# Булевы операции\n",
    "a = torch.tensor([[1, 2, 3], [10, 20, 30], [100, 200, 300]])\n",
    "b = torch.tensor([[-1, -2, -3], [-10, -20, -30], [100, 200, 300]])\n",
    "print(a == b)\n",
    "print(a != b)\n",
    "print(a < b)\n",
    "print(a > b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137d90dd",
   "metadata": {},
   "source": [
    "К тензорам можно поэлементно применять **стандартные функции**, которые являются методами класса тензоров. Как и выше, есть два способа записи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79f8c1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8415,  0.9093,  0.1411],\n",
      "        [-0.5440,  0.9129, -0.9880],\n",
      "        [-0.5064, -0.8733, -0.9998]]) ,\n",
      " tensor([[ 0.8415,  0.9093,  0.1411],\n",
      "        [-0.5440,  0.9129, -0.9880],\n",
      "        [-0.5064, -0.8733, -0.9998]])\n",
      "tensor([[ 0.5403, -0.4161, -0.9900],\n",
      "        [-0.8391,  0.4081,  0.1543],\n",
      "        [ 0.8623,  0.4872, -0.0221]]) ,\n",
      " tensor([[ 0.5403, -0.4161, -0.9900],\n",
      "        [-0.8391,  0.4081,  0.1543],\n",
      "        [ 0.8623,  0.4872, -0.0221]])\n",
      "tensor([[2.7183e+00, 7.3891e+00, 2.0086e+01],\n",
      "        [2.2026e+04, 4.8517e+08, 1.0686e+13],\n",
      "        [       inf,        inf,        inf]]) ,\n",
      " tensor([[2.7183e+00, 7.3891e+00, 2.0086e+01],\n",
      "        [2.2026e+04, 4.8517e+08, 1.0686e+13],\n",
      "        [       inf,        inf,        inf]])\n",
      "tensor([[0.0000, 0.6931, 1.0986],\n",
      "        [2.3026, 2.9957, 3.4012],\n",
      "        [4.6052, 5.2983, 5.7038]]) ,\n",
      " tensor([[0.0000, 0.6931, 1.0986],\n",
      "        [2.3026, 2.9957, 3.4012],\n",
      "        [4.6052, 5.2983, 5.7038]])\n",
      "tensor([[  1,   2,   3],\n",
      "        [ 10,  20,  30],\n",
      "        [100, 200, 300]]) ,\n",
      " tensor([[  1,   2,   3],\n",
      "        [ 10,  20,  30],\n",
      "        [100, 200, 300]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3], [10, 20, 30], [100, 200, 300]])\n",
    "print(a.sin(),\",\\n\",torch.sin(a))\n",
    "print(a.cos(),\",\\n\",torch.cos(a))\n",
    "print(a.exp(),\",\\n\",torch.exp(a))\n",
    "print(a.log(),\",\\n\",torch.log(a))\n",
    "b = -a\n",
    "print(b.abs(),\",\\n\",torch.abs(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df5b7e1",
   "metadata": {},
   "source": [
    "### Тензоры: манипуляция с формой матриц\n",
    "\n",
    "Часто требуется изменить форму тензора, не меняя сами значения тензора. \n",
    "\n",
    "|`Method` |\t`One-line description`|\n",
    "|:-:|:-:|\n",
    "|`torch.reshape(input, shape)`|Смена формы тензора input в форму shape (если возможно), также можно использовать torch.Tensor.reshape().|\n",
    "|`torch.Tensor.view(shape)`|\tПредставление тензора в другой форме.|\n",
    "|`torch.stack(tensors, dim=0)`|Конкатенация тензоров вдоль новой размерности (dim), все тензоры одного размера.|\n",
    "|`torch.squeeze(input)` |Сжимает input удаляя все размерности со значением 1.|\n",
    "|`torch.unsqueeze(input, dim)` |Возвращает input с новой размерностью dim со значением 1.|\n",
    "|`torch.permute(input, dims)`| Новый вид тензора input с перестановками  порядка размерностей, указанному dims.|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0649a78b",
   "metadata": {},
   "source": [
    "Для смены формы тензора используется метод view(), это аналог np.reshape(). Возвращаемый тензор является представлением (view) исходного тензора,  изменения в новом тензоре изменят и исходный тензор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ab3ea543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "b = torch.tensor([[1,2,3], [4,5,6]])\n",
    "c = b.view(3, 2)\n",
    "print(c)\n",
    "print(b.view(-1).shape) # к одномерному массиву"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "71cdf5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1, 50,  3],\n",
       "         [ 4,  5,  6]]),\n",
       " tensor([[ 1, 50],\n",
       "         [ 3,  4],\n",
       "         [ 5,  6]]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# изменения c изменят и b\n",
    "c[0,1]=50\n",
    "b,c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467f1921",
   "metadata": {},
   "source": [
    "Метод torch.reshape() также как и используется для смены формы torch.view() (отличие см. в документации). В большинстве случаев возвращаемый тензор является представлением (view) исходного тензора, изменения в новом тензоре изменят и исходный тензор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d26b6263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6., 7.]) torch.Size([8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2., 3.],\n",
       "         [4., 5., 6., 7.]]),\n",
       " torch.Size([2, 4]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0., 8.)\n",
    "print(x, x.shape)\n",
    "\n",
    "x_reshaped = x.reshape(2,4)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2dd0ac95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 4., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([[0., 4., 2., 3.],\n",
       "         [4., 5., 6., 7.]]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped[0,1] = 4\n",
    "x,x_reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f689eb",
   "metadata": {},
   "source": [
    "Тензоры одинаковой размерности можно состыковывать командой `torch.stack()` с указанием размерности, вдоль которой будет стыковка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60fcef54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2., 3., 4., 5., 6., 7.],\n",
       "        [0., 1., 2., 3., 4., 5., 6., 7.],\n",
       "        [0., 1., 2., 3., 4., 5., 6., 7.],\n",
       "        [0., 1., 2., 3., 4., 5., 6., 7.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.arange(0., 8.)\n",
    "\n",
    "# стыковка тензоров\n",
    "x_stacked = torch.stack([x, x, x, x], dim=0) # стыковка как строк. Можно сменить на dim=1 \n",
    "x_stacked\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dea930",
   "metadata": {},
   "source": [
    "Часто при работе с массивом могут получаться лишние скобки, или ненужные размерности, вдоль которых лежит всего один элемент. Эти скобки можно убрать методом  `torch.squeeze()`. Либо наоборот эти скобки можно добавить методом `torch.unsqueeze()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fce0dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный тензор: tensor([[1, 2, 3, 4, 5]])\n",
      "Размер: torch.Size([1, 5])\n",
      "\n",
      "Новый тензор: tensor([1, 2, 3, 4, 5])\n",
      "Размер: torch.Size([5])\n",
      "\n",
      "New tensor: tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5]])\n",
      "New shape: torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1,2,3,4,5]])\n",
    "print(f\"Исходный тензор: {x}\")\n",
    "print(f\"Размер: {x.shape}\")\n",
    "\n",
    "# убрать лишнюю размерность\n",
    "x_squeezed = x.squeeze()\n",
    "print(f\"\\nНовый тензор: {x_squeezed}\")\n",
    "print(f\"Размер: {x_squeezed.shape}\")\n",
    "\n",
    "## добавить\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=1) # можно указать, какую рамерность добавить\n",
    "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e22a5f",
   "metadata": {},
   "source": [
    "Также есть возможность сменить порядок размерности, указав явно новый порядок. На выходе будет представление того же самого тензора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19d70de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([120, 160, 3])\n",
      "New shape: torch.Size([3, 120, 160])\n"
     ]
    }
   ],
   "source": [
    "x_original = torch.rand(size=(120, 160, 3))\n",
    "\n",
    "x_permuted = x_original.permute(2, 0, 1) # смена осей 0->1, 1->2, 2->0\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0962d953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1],\n",
      "         [2, 3]],\n",
      "\n",
      "        [[4, 5],\n",
      "         [6, 7]]])\n",
      "tensor([[ 4,  6],\n",
      "        [ 8, 10]])\n",
      "tensor([[ 2,  4],\n",
      "        [10, 12]])\n",
      "torch.return_types.max(\n",
      "values=tensor([[4, 5],\n",
      "        [6, 7]]),\n",
      "indices=tensor([[1, 1],\n",
      "        [1, 1]]))\n"
     ]
    }
   ],
   "source": [
    "# Прочие примеры\n",
    "b=torch.tensor(list(range(8)))\n",
    "print(b.view(2, 2, 2))\n",
    "c = b.view(2, 2, 2)\n",
    "print(c.sum(0)) \n",
    "print(c.sum(1))\n",
    "print(c.max(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ba7707",
   "metadata": {},
   "source": [
    "### Тензоры: индексация\n",
    "\n",
    "Индексация точная такая же, как и в NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0e3abd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2941, 0.1218, 0.2471])\n",
      "tensor([0.2941, 0.1218, 0.2471])\n",
      "tensor([[[0.2941, 0.1218],\n",
      "         [0.5342, 0.9453]]])\n",
      "tensor([[[0.2941, 0.1218, 0.2471],\n",
      "         [0.5342, 0.9453, 0.6203]]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "a = torch.rand(size=(1,3,3))\n",
    "print(a[0, 0])\n",
    "print(a[0][0])\n",
    "print(a[:,0:2, 0:2])\n",
    "print(a[:,0:2, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa994729",
   "metadata": {},
   "source": [
    "Можно также использовать логическую индексацию, но результатом будет одномерный массив значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86fb9663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 2],\n",
      "         [3, 4, 5],\n",
      "         [6, 7, 8]]])\n",
      "tensor([[[8, 7, 6],\n",
      "         [5, 4, 3],\n",
      "         [2, 1, 0]]])\n",
      "tensor([0, 1, 2, 3, 5, 6, 7, 8])\n",
      "tensor([4, 3, 2, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(9).reshape(1,3,3)\n",
    "b = torch.arange(8,-1,-1).reshape(1,3,3)\n",
    "print(a)\n",
    "print(b)\n",
    "print(a[a != b])\n",
    "print(b[a >= b])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6519e851",
   "metadata": {},
   "source": [
    "## Тензоры: матричные операции и связь с NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd56c658",
   "metadata": {},
   "source": [
    "**Перевод массива из NumPy в PyTorch**: с помощью метода torch.from_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3328e07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy:  [[0.99992837 0.18847704 0.99989629]\n",
      " [0.59303675 0.74072888 0.99108414]\n",
      " [0.59364077 0.02347271 0.17819951]]\n",
      "Tensor:  tensor([[0.9999, 0.1885, 0.9999],\n",
      "        [0.5930, 0.7407, 0.9911],\n",
      "        [0.5936, 0.0235, 0.1782]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.random.rand(3, 3)\n",
    "b = torch.from_numpy(a)\n",
    "print(\"NumPy: \",a)\n",
    "print(\"Tensor: \",b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ad3607",
   "metadata": {},
   "source": [
    "Важно отметим, что по умолчанию NumPy массив имеет тип данных float64 и при конвертации в **PyTorch** тензор этот тип сохранится.\n",
    "\n",
    "Однако, базовым типом данных для вычислений в **PyTorch** является float32. Для конвертации\n",
    "    \n",
    "    NumPy array (float64) -> PyTorch tensor (float64) -> PyTorch tensor (float32)\n",
    "    \n",
    "можно использовать команду вида `tensor = torch.from_numpy(array).type(torch.float32)`.\n",
    "\n",
    "\n",
    "Ещё одна *Особенность* в том, что переменные a и b, заданные выше, будут ссылаться на одно и тоже место в памяти, то есть измение одного массива будет менять и другой. Однако, если менять тип данных, то ссылка будет уже на разные места в памяти. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d8dca3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19.          0.18847704  0.99989629]\n",
      " [ 0.59303675  0.74072888  0.99108414]\n",
      " [ 0.59364077  0.02347271  0.17819951]] \n",
      " tensor([[19.0000,  0.1885,  0.9999],\n",
      "        [ 0.5930,  0.7407,  0.9911],\n",
      "        [ 0.5936,  0.0235,  0.1782]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "b[0,0]=10\n",
    "a[0,0]=a[0,0]+9\n",
    "print(a,'\\n',b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "210d5a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Хотя при такой операции не меняется\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "\n",
    "# меняем массив, тензор не меняется\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac4700c",
   "metadata": {},
   "source": [
    "**Перевод из PyTorch в NumPy:** с помощью метода torch.numpy(). По умолчанию тензор создается с типом данных float32. NumPy массив будет иметь тот же тип данных. В данном случае также оба массива будут ссылаться на одно и то же место в памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9378b3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6328181 , 0.58345234, 0.9202209 ],\n",
       "       [0.16245031, 0.26275432, 0.60898954]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(2, 3)\n",
    "x = a.numpy()\n",
    "print(type(x))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b299d861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.        ,  0.58345234,  0.9202209 ],\n",
       "       [ 0.16245031,  0.26275432,  0.60898954]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0,0]=10\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04c6b176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.0000,  0.5835,  0.9202],\n",
       "        [ 0.1625,  7.0000,  0.6090]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1,1]=7\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4486fa12",
   "metadata": {},
   "source": [
    "### Тензоры: использование в ИНС\n",
    "\n",
    "Один из стандартных компонентов ИНС - это полносвязный слой. Он реализуется модулем `torch.nn.Linear()`, и работает по формуле\n",
    "\n",
    "$$\n",
    "y=x \\cdot A^T+b.\n",
    "$$\n",
    "\n",
    "Здесь\n",
    "    \n",
    "    x входные данные\n",
    "    A матрица с параметрами\n",
    "    b смещение, тоже вектор в параметрами\n",
    "    y выходные данные\n",
    "\n",
    "**Пример** Реализовать функцию `forward_pass(X, w)` ($w_0$ входит в $w$) для одного нейрона (с сигмоидой) с помощью PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f15b4cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 2])\n",
      "\n",
      "Output:\n",
      "tensor([[-0.2539,  0.2555,  0.3376,  0.4656, -0.0777,  1.0456],\n",
      "        [-0.0635, -0.0787,  0.0365,  0.2090, -0.2524,  0.7780],\n",
      "        [-0.2150,  0.1119, -0.0063,  0.1786, -0.2141,  0.7447]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape: torch.Size([3, 6])\n",
      "Output 2:\n",
      "tensor([[-0.2539,  0.2555,  0.3376,  0.4656, -0.0777,  1.0456],\n",
      "        [-0.0635, -0.0787,  0.0365,  0.2090, -0.2524,  0.7780],\n",
      "        [-0.2150,  0.1119, -0.0063,  0.1786, -0.2141,  0.7447]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "torch.manual_seed(42)\n",
    "x = torch.rand(size=(3,2), dtype=torch.float32)\n",
    "\n",
    "# создание полносвязного слоя\n",
    "linear = torch.nn.Linear(in_features=2, # in_features равна внутренней размерности входных данных\n",
    "                         out_features=6) # out_features = размерность вектора выходных данных\n",
    "\n",
    "output = linear(x)\n",
    "print(f\"Input shape: {x.shape}\\n\")\n",
    "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")\n",
    "\n",
    "# Сравнение с непосредственной реализацией\n",
    "A = linear.weight \n",
    "b = linear.bias  \n",
    "\n",
    "output2 = torch.mm(tensor_A,A.T)+b\n",
    "print(f\"Output 2:\\n{output2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2ac9bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: tensor([1.0000, 0.9985, 0.0474])\n"
     ]
    }
   ],
   "source": [
    "### Куда ???\n",
    "\n",
    "def forward_pass(X, w):\n",
    "    return torch.sigmoid(X.mv(w.view(-1)))\n",
    "    #либо X @ w\n",
    "    \n",
    "X = torch.FloatTensor([[-5, 5], [2, 3], [1, -1]])\n",
    "w = torch.FloatTensor([[-0.5], [2.5]])\n",
    "result = forward_pass(X, w)\n",
    "print('result: {}'.format(result))\n",
    "# result: tensor([1.0000, 0.9985, 0.0474])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea324a14",
   "metadata": {},
   "source": [
    "## Особенности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ba251f",
   "metadata": {},
   "source": [
    "Methods which end in an underscore change the tensor in-place. \n",
    "That means that no new memory is being allocated by doing the operation, \n",
    "which in general increase performance, but can lead to problems and worse performance in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d188a876",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2fe326",
   "metadata": {},
   "source": [
    "AutoGrad (Automatic Gradients, автоматическое взятие градиентов) -- это модуль PyTorch, отвечающий за взятие производных. Из тензоров и дейсвтий с ними формируется функция многих переменных $Q$, у которой можно вычислить производные по всем интересующим переменным в текущей точке методом `backward()` (интересующие переменные можно отметимть при задании тензоров  указав опцию `requires_grad=True`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cbf3cba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((3, 1), requires_grad=True)\n",
    "w = torch.randn((3, 3), requires_grad=True)\n",
    "b = torch.randn((3, 1), requires_grad=False)\n",
    "\n",
    "y = (w @ x).add(b)\n",
    "\n",
    "Q = y.sum() # итоговая функция\n",
    "# берём градиенты по всем \"листьям\" - в данном случае это тензоры x, w\n",
    "Q.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a75f8fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0293, -0.0408, -0.0260],\n",
      "        [ 0.6972,  0.3295, -1.0734],\n",
      "        [-1.0426, -0.6452,  0.9046]], requires_grad=True)\n",
      "tensor([[-1.4422],\n",
      "        [-0.1731],\n",
      "        [ 1.5914]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9c70fc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3747],\n",
      "        [-0.3565],\n",
      "        [-0.1949]]) | <class 'torch.Tensor'>\n",
      "tensor([[-1.4422, -0.1731,  1.5914],\n",
      "        [-1.4422, -0.1731,  1.5914],\n",
      "        [-1.4422, -0.1731,  1.5914]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad,\"|\",type(x.grad))\n",
    "\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012fc455",
   "metadata": {},
   "source": [
    "В данном случае функция $Q$ имеет вид\n",
    "\n",
    "$$Q = \\sum_{j=1}^m (\\sum_{j=1}^n w_{i,j} x_j + b_i)\n",
    "$$\n",
    "\n",
    "Значит\n",
    "\n",
    "$$\\frac{\\partial Q}{\\partial x_j} = \\sum_{j=1}^m  w_{i,j}, \\quad\n",
    "\\frac{\\partial Q}{\\partial w_{i,j}} = x_j\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e34cc45",
   "metadata": {},
   "source": [
    "Важно обратить внимание, что градиенты лежат в поле `.grad` у тех тензоров, по которым брали эти градиенты."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b38c66",
   "metadata": {},
   "source": [
    "- Объявите тензор `a` размера (2, 3, 4) и тензор `b` размера (1, 8, 3), иницилизируйте их случайно равномерно \n",
    "- Затем измените форму тензора `b`, чтобы она совпадала с формой тензора `a`, получите тензор `c`  \n",
    "- Объявите тензор `L = torch.mean((c - a) `**` 2)` и посчитайте градиент `L` по `c` ( то есть $\\frac{\\partial{L}}{\\partial{c}})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "197d1cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2144, -0.0658,  0.0049,  0.1751],\n",
       "         [ 0.0227,  0.0932,  0.0030, -0.0307],\n",
       "         [-0.1526, -0.0410, -0.0062,  0.0918]],\n",
       "\n",
       "        [[-0.1257, -0.0128,  0.0008, -0.0187],\n",
       "         [ 0.1459, -0.0208, -0.0793,  0.0358],\n",
       "         [-0.0175,  0.0957,  0.1700,  0.0304]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn((2, 3, 4))\n",
    "c = torch.randn((2, 3, 4), requires_grad=True)\n",
    "L = torch.mean((c - a)**2)\n",
    "L.backward()\n",
    "c.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1711f5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
